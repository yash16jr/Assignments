{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab9a0f0-8b4f-4bce-babd-72d5eeaf9150",
   "metadata": {},
   "source": [
    "## <u>Ques1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199d802-9bd8-4b7b-a11c-29e934e3771f",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2a0b9-2d74-4267-a204-139247bbfb72",
   "metadata": {},
   "source": [
    "Ans1. Web scraping is the process of extracting data from websites using automated software or tools. It is used to collect data from various websites for purposes such as data collection, content aggregation, and data analysis.\n",
    "\n",
    "Three areas where web scraping is commonly used to get data are:\n",
    "\n",
    "E-commerce: Web scraping is used to collect product information, prices, and reviews from e-commerce websites. This data can be used for competitor analysis, price monitoring, and market research.\n",
    "\n",
    "Social media: Web scraping is used to collect data from social media platforms like Twitter, Facebook, and LinkedIn. This data can be used for sentiment analysis, trend analysis, and social media monitoring.\n",
    "\n",
    "Research: Web scraping is used in academic research to collect data from various websites, including government databases, news websites, and research papers. This data can be used for analysis and data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a2164-b1fb-4a36-aa7c-cb707c55df25",
   "metadata": {},
   "source": [
    "## <u>Ques2</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87129a67-b5dd-4116-aa1d-bdf29468207f",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fb249-cf04-4590-8f34-05bfa1138630",
   "metadata": {},
   "source": [
    "<u>Ans2.</u> Different methods used for web scraping are:\n",
    "\n",
    "\n",
    "HTML parsing: This method involves parsing the HTML code of a website to extract specific data. This can be done using libraries such as Beautiful Soup or lxml in Python.\n",
    "\n",
    "Web API: Some websites offer Web APIs that allow developers to access data in a structured format. This method involves sending requests to the API and receiving data in a structured format such as JSON or XML.\n",
    "\n",
    "Headless browsing: This method involves using a headless browser to interact with a website and extract data. A headless browser is a browser that doesn't have a user interface, allowing it to be controlled programmatically.\n",
    "\n",
    "DOM traversal: This method involves traversing the Document Object Model (DOM) of a website to extract data. The DOM is a tree-like representation of the HTML code of a website, and can be manipulated using JavaScript.\n",
    "\n",
    "Scraping using browser extensions: Some browser extensions like Web Scraper or Data Miner can be used for web scraping by selecting specific elements on a web page and extracting data from them.\n",
    "\n",
    "Machine learning-based approaches: Machine learning algorithms can be used to extract specific data from websites by training models on relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba420803-9b3c-406f-9f02-be74752afa70",
   "metadata": {},
   "source": [
    "## <u>Ques3</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bfce8-74de-4f98-8afc-79bcd1269888",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e15266-7d17-4eb8-862c-4cff28c3f753",
   "metadata": {},
   "source": [
    "<u>Ans3. </u>Beautiful Soup is a Python library used for web scraping purposes. It is used to extract data from HTML and XML files. Beautiful Soup provides a simple and intuitive way to navigate, search, and modify the parse tree generated from the HTML source code.\n",
    "\n",
    "Beautiful Soup is used for several reasons:\n",
    "\n",
    "Ease of use: Beautiful Soup provides a simple and easy-to-use interface for parsing HTML and XML files, which makes it accessible for beginners in web scraping.\n",
    "\n",
    "Robust parsing: Beautiful Soup can handle poorly formatted HTML code, which can be challenging for other parsing libraries.\n",
    "\n",
    "Integration with other Python libraries: Beautiful Soup can be easily integrated with other Python libraries such as Requests for making HTTP requests and Pandas for data analysis.\n",
    "\n",
    "Compatibility: Beautiful Soup is compatible with both Python 2 and Python 3, making it accessible to a wide range of developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdce8e5-12b1-49c9-90da-a17dd9c0dd7f",
   "metadata": {},
   "source": [
    "## <u>Ques4</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22751d-1fb9-4912-9816-b7a9078bd738",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3d9d3-3745-42c7-8e40-23efa8109696",
   "metadata": {},
   "source": [
    "<u> Ans4.</u> \n",
    "\n",
    "\n",
    "Flask is used due to the following reasons:\n",
    "\n",
    "Data visualization: Flask can be used to build a web application that presents the scraped data in an easy-to-understand format, such as graphs or charts.\n",
    "\n",
    "User interface: Flask can be used to build a user interface for the web scraping project, allowing users to interact with the data in a more intuitive way.\n",
    "\n",
    "Automation: Flask can be used to automate the web scraping process, allowing for regular updates of the data.\n",
    "\n",
    "Integration: Flask can be easily integrated with other Python libraries, allowing for more advanced data analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b0f71-3af4-4d12-8f11-7e0f86e30689",
   "metadata": {},
   "source": [
    "## <u>Ques5</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a2815-4369-47ca-bfa0-716db3a4ccc8",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d67b7b-d52c-4b9a-8ebd-26672e831067",
   "metadata": {},
   "source": [
    "<u>Ans5.</u>\n",
    "\n",
    "1). First one is Code Pipeline, which is used to connect github repository.<br>\n",
    "2). Second is Beanstalk, which is used to connect with code pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d402e-c016-4243-a15f-da4f1bfb6a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fb02d-1aab-4fcb-bd44-a517e6bcfcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
